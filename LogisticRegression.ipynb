{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvMMtReyVLpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpP6ZCcoVG5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "4152fef2-3c90-4a74-dc70-cbd33a26ae85"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import time\n",
        "\n",
        "# Set this variable to True to train on entire dataset. This means we have no test set to check accuracy with. No accuracy output\n",
        "# Set it to False to do a train_test_split. This means we have a test set that we can check accuracy with.\n",
        "trainOnEntireDataSet = False\n",
        "\n",
        "# Stemmer function to reduce feature space\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # To allow for easier cross platform execution, check if this file is being run in a Google Colab notebook\n",
        "    inColab = 'google.colab' in sys.modules\n",
        "\n",
        "    #Import datasets\n",
        "    if inColab:\n",
        "        trainingData = pd.read_csv(\"./gdrive/My Drive/train.csv\")\n",
        "        stopWords = [line.rstrip('\\n') for line in open(\"./gdrive/My Drive/stopwords.txt\")]\n",
        "        testData = pd.read_csv(\"./gdrive/My Drive/test.csv\")\n",
        "\n",
        "    else:\n",
        "        trainingData = pd.read_csv(\"train.csv\")\n",
        "        stopWords = [line.rstrip('\\n') for line in open(\"stopwords.txt\")]\n",
        "        testData = pd.read_csv(\"test.csv\")\n",
        "\n",
        "    # Adjust data sets if we're producing a file to submit to Kaggle \n",
        "    if trainOnEntireDataSet:\n",
        "        trainingData = trainingData.sample(frac=1)\n",
        "        X_train = trainingData['review']\n",
        "        y_train = trainingData['sentiment']\n",
        "        X_test = testData['review']\n",
        "        y_test = None\n",
        "\n",
        "    else:\n",
        "        trainingData = trainingData.sample(frac=1)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(trainingData['review'], trainingData['sentiment'], train_size=0.8, test_size=0.2)\n",
        "    \n",
        "    startTime = time.time()\n",
        "\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "    # Do count vectorization\n",
        "    vectorizer = CountVectorizer(strip_accents='ascii',  binary=False)\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Calculate term-frequencies and inverse document frequencies\n",
        "    tf_idf_vectorizer = TfidfVectorizer()\n",
        "    vectors_train_idf = tf_idf_vectorizer.fit_transform(X_train)\n",
        "    vectors_test_idf = tf_idf_vectorizer.transform(X_test)\n",
        "\n",
        "    # Normalize data\n",
        "    normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "    vectors_train_normalized = normalizer_train.transform(vectors_train_idf)\n",
        "    vectors_test_normalized = normalizer_train.transform(vectors_test_idf)\n",
        "\n",
        "    # Run a GridSearchCV to determine optimal hyper-parameters\n",
        "    nFolds = 5\n",
        "    parameters = {'C': [9], 'max_iter': [10000]}\n",
        "    clf = LogisticRegression()\n",
        "    clf = GridSearchCV(clf, parameters, cv=nFolds, n_jobs=-1, verbose=10)\n",
        "    clf.fit(vectors_train_normalized, y_train)\n",
        "    print(\"Best score found during GridSearchVH\", clf.best_score_)\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"%s: %r\" % (param_name, clf.best_params_[param_name]))\n",
        "    y_pred = clf.predict(vectors_test_normalized)\n",
        "\n",
        "    print(\"Runtime =\", time.time() - startTime, \"seconds\")\n",
        "\n",
        "    # Save file if doing Kaggle submission, if not then print metrics\n",
        "    if trainOnEntireDataSet:\n",
        "        if inColab:\n",
        "            from google.colab import files\n",
        "\n",
        "            with open('submission.txt', 'w') as f:\n",
        "                f.write('id,sentiment\\n')\n",
        "                for x in range(len(y_pred)):\n",
        "                    f.write(str(x) + \",\" + y_pred[x] + \"\\n\")\n",
        "        else:\n",
        "            with open('submission.csv', 'w') as f:\n",
        "                f.write('id,sentiment\\n')\n",
        "                for x in range(len(y_pred)):\n",
        "                    f.write(str(x) + \",\" + y_pred[x] + \"\\n\")\n",
        "    else:\n",
        "        print(\"Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   21.1s remaining:   14.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score found during GridSearchVH 0.8784333333333333\n",
            "C: 9\n",
            "max_iter: 10000\n",
            "Runtime = 46.13547897338867 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPkLotQ0WUsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('submission.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}